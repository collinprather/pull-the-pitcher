{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "> Command-line script, which utilizes the `data_processing` module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti \n",
    "from pull_the_pitcher.data import processing\n",
    "from pull_the_pitcher.data.acquisition import query_db\n",
    "from pull_the_pitcher.data.processing import last\n",
    "from fastscript import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "embedding_cols = [\"game_pk\", \"game_type\", \"pitcher\", \"pitcher_team_year\"]\n",
    "feature_cols = [\"post_bat_score\", \"score_diff\", \"end_inning\", \"inning\", \"postouts\", \"cum_sb_ratio\",\n",
    "                \"times_thru_order\", \"post_total_runners\", \"tying_run_on\", \"pitch_total\", \"post_opposite_hand\",\n",
    "                \"walk\", 'walk_cumsum', 'strikeout_cumsum', 'home_run_cumsum', 'bases_cumsum']\n",
    "cols = embedding_cols + feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# adding targets to each\n",
    "def add_targets(starts: List):\n",
    "    \"\"\"adding target as last col to each start\"\"\"\n",
    "    for i, start in enumerate(starts):\n",
    "        y = np.zeros((start.shape[0], 1))\n",
    "        y[-1, 0] = 1\n",
    "        starts[i] = np.concatenate([start, y], axis=1)\n",
    "    return starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def stack_into_df(starts: List):\n",
    "    # concatenating into big dfs\n",
    "    df = pd.DataFrame(np.concatenate(starts, axis=0), columns=cols+[\"pulled\"])\n",
    "\n",
    "    # correcting data types\n",
    "    for col in feature_cols + [\"pulled\"]:\n",
    "        df[col] = df[col].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def scale(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    # scaling data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train[feature_cols])\n",
    "    train[feature_cols] = scaler.transform(train[feature_cols])\n",
    "    test[feature_cols] = scaler.transform(test[feature_cols])\n",
    "    return train, test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def encode_col(train, valid, col=\"pitcher_id\"):\n",
    "    \n",
    "    # encoding movies and user ids with continous ids\n",
    "    train_ids = np.sort(np.unique(train[col].values))\n",
    "\n",
    "    # number of unique ids\n",
    "    num_users = len(train_ids)\n",
    "    print(f\"There are {num_users} unique {col}'s in this dataset\")\n",
    "\n",
    "    # making changes in df\n",
    "    id2idx = {o:i for i,o in enumerate(train_ids)}\n",
    "    train[col] = train[col].apply(lambda x: id2idx[x])\n",
    "    valid[col] = valid[col].apply(lambda x: id2idx.get(x, -1)) # -1 for users not in training\n",
    "    \n",
    "    # getting rid of users not in training set\n",
    "    valid = valid[valid[col] >= 0].copy()\n",
    "    return train, valid, id2idx\n",
    "\n",
    "\n",
    "def encode_embedding_cols(train, test, cols=[\"game_pk\", \"game_type\", \"pitcher\", \"pitcher_team_year\"]):\n",
    "    # adding a row of zeros that act as \"null\" or \"unknown\"\n",
    "    # embeddings for the zero-padded rows\n",
    "    zero_row = pd.DataFrame(np.zeros((1, train.shape[1])), columns=train.columns)\n",
    "    train = pd.concat([zero_row, train], axis=0)\n",
    "    test = pd.concat([zero_row, test], axis=0)\n",
    "\n",
    "    # changing dtypes in order to encode for embeddings\n",
    "    for cat in [\"game_type\", \"pitcher_team_year\"]:\n",
    "        train[cat] = train[cat].astype(str)\n",
    "        test[cat] = test[cat].astype(str)\n",
    "        \n",
    "    mappers = dict()\n",
    "    # not embedding game_pk, just switching to int for easier type casting\n",
    "    for col in cols:\n",
    "        train, test, mapper = encode_col(train, test, col=col)\n",
    "        mappers[col] = mapper\n",
    "    \n",
    "    return train, test, mappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "at_bat_aggs = {\"balls\": \"max\",\n",
    "                \"strikes\": \"max\",\n",
    "                \"pitch_number\": \"max\",\n",
    "                \"post_bat_score\": last,\n",
    "                \"post_fld_score\": last,\n",
    "                \"events\": \"max\",\n",
    "                \"postouts\": last,\n",
    "                \"post_on_1b\": last,\n",
    "                \"post_on_2b\": last,\n",
    "                \"post_on_3b\": last,\n",
    "                \"game_type\": last,\n",
    "                \"home_team\": last,\n",
    "                \"away_team\": last,\n",
    "                \"inning\": last,\n",
    "                \"inning_topbot\": last,\n",
    "               \"post_opposite_hand\": last,\n",
    "               \"game_year\": last}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@call_parse\n",
    "def prep_data_for_modeling(\n",
    "    db_path: Param(\n",
    "        help=\"Path to db with statcast data\", type=str\n",
    "    ) = \"./data/raw/statcast_pitches.db\",\n",
    "    years: Param(help=\"Year of statcast data to process\", type=str, nargs=\"+\") = [\n",
    "        \"2019\"\n",
    "    ],\n",
    "    verbose: Param(\n",
    "        help=\"Whether to print out updates on processing\", type=bool_arg\n",
    "    ) = True,\n",
    "    train_test_split_by: Param(\n",
    "        help=\"How to split into train/test sets. One of {'start', 'year'}.\", type=str\n",
    "    ) = \"start\",\n",
    "    test_size: Param(help=\"Percent of data to allocate to test set\", type=float) = 0.25,\n",
    "    output_path: Param(\n",
    "        help=\"Path to save processed csv files\", type=str\n",
    "    ) = \"./data/processed/\",\n",
    "):\n",
    "    # getting all dfs from all years into a single df\n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        df_year = query_db(db_path, year, verbose=verbose)\n",
    "        dfs.append(df_year)\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # identifying eligible game-pitcher-year combos\n",
    "    games_pitchers_years = processing.get_games_pitchers_years(df, verbose)\n",
    "\n",
    "    # deciding which outings to allocate to train or test set\n",
    "    if train_test_split_by == \"start\":\n",
    "        # pre-determining which starts will go into train/test sets\n",
    "        test_flags = bernoulli(p=test_size).rvs(\n",
    "            len(games_pitchers_years), random_state=742\n",
    "        )\n",
    "        train_year = test_year = years\n",
    "    elif train_test_split_by == \"year\":\n",
    "        # identifying year of test starts\n",
    "        test_year = list(np.sort(df[\"game_date\"].str[:4].unique())[-1])\n",
    "        train_year = list(set(years).difference(set([test_year])))\n",
    "        test_flags = [\n",
    "            1 if str(y) == test_year[0] else 0 for (g, p, y) in games_pitchers_years\n",
    "        ]\n",
    "    else:\n",
    "        # no starts go to test set\n",
    "        test_flags = np.zeros(len(games_pitchers))\n",
    "\n",
    "    # processing dfs of data from eligible pitchers\n",
    "    train_starts = []\n",
    "    test_starts = []\n",
    "    for i, (test_flag, (g, p, y)) in enumerate(zip(test_flags, games_pitchers_years)):\n",
    "        if verbose:\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Just processed {i}th start.\")\n",
    "\n",
    "        cleaned_df = processing.preliminary_clean(df, g, p)\n",
    "        agged_df = processing.aggregate_at_bats(cleaned_df, at_bat_aggs)\n",
    "        feature_engineered_df = processing.feature_engineering(agged_df)\n",
    "\n",
    "        # making sure starting pitcher is in AL -> this _should_ no longer be necessary\n",
    "        if feature_engineered_df.shape[0] > 0:\n",
    "            if test_flag:\n",
    "                test_starts.append(feature_engineered_df[cols])\n",
    "            else:\n",
    "                train_starts.append(feature_engineered_df[cols])\n",
    "        else:\n",
    "            print(\"empty df\")\n",
    "\n",
    "    # adding binary targets (pitcher always removed in last at-bat)\n",
    "    train_starts = add_targets(train_starts)\n",
    "    test_starts = add_targets(test_starts)\n",
    "\n",
    "    # stacking starts into dfs for scaling and categorical encoding\n",
    "    train = stack_into_df(train_starts)\n",
    "    test = stack_into_df(test_starts)\n",
    "\n",
    "    # standard scaling (mean of 0, sd of 1)\n",
    "    train, test, scaler = scale(train, test)\n",
    "\n",
    "    # encoding categoricals for embeddings later\n",
    "    train, test, mappers = encode_embedding_cols(train, test, cols=[\"pitcher\"])\n",
    "\n",
    "    # saving train, test sets, along with categorical mapper to output path\n",
    "    train.to_csv(f\"{output_path}/train_{'_'.join(train_year)}.csv\", index=False)\n",
    "    test.to_csv(f\"{output_path}/test_{'_'.join(test_year)}.csv\", index=False)\n",
    "    with open(\n",
    "        f\"{output_path}/mappers_{'_'.join(train_year + test_year)}.pkl\", \"wb\"\n",
    "    ) as f:\n",
    "        pickle.dump(mappers, f)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"{years} data ready for modeling and saved at {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2019-07-07 to 2019-07-12\n",
      "Completed sub-query from 2019-07-13 to 2019-07-18\n",
      "Completed sub-query from 2019-07-19 to 2019-07-20\n"
     ]
    }
   ],
   "source": [
    "! query_statcast --start_dt 2019-07-07 --end_dt 2019-07-20 --output_type db --output_path /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcom.apple.launchd.82pLsk9OX7\u001b[m\u001b[m \u001b[34mrecsim\u001b[m\u001b[m\r\n",
      "\u001b[34mcom.google.Keystone\u001b[m\u001b[m          statcast_pitches.db\r\n",
      "\u001b[34mpowerlog\u001b[m\u001b[m                     t.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying db at ../data/raw/statcast_pitches.db now.\n",
      "In this dataset, there are 2429 total games.\n",
      "There are 2804 ineligible starts in the dataset (either 'openers' or an NL team).\n",
      "There are 2054 total eligible game-pitcher combinations in this dataset.\n",
      "Just processed 0th start.\n",
      "Just processed 100th start.\n",
      "Just processed 200th start.\n",
      "Just processed 300th start.\n",
      "Just processed 400th start.\n",
      "Just processed 500th start.\n",
      "Just processed 600th start.\n",
      "Just processed 700th start.\n",
      "Just processed 800th start.\n",
      "Just processed 900th start.\n",
      "Just processed 1000th start.\n",
      "Just processed 1100th start.\n",
      "Just processed 1200th start.\n",
      "Just processed 1300th start.\n",
      "Just processed 1400th start.\n",
      "Just processed 1500th start.\n",
      "Just processed 1600th start.\n",
      "Just processed 1700th start.\n",
      "Just processed 1800th start.\n",
      "Just processed 1900th start.\n",
      "Just processed 2000th start.\n",
      "There are 229 unique pitcher's in this dataset\n",
      "['2019'] data ready for modeling and saved at /tmp.\n"
     ]
    }
   ],
   "source": [
    "prep_data_for_modeling(db_path=\"../data/raw/statcast_pitches.db\",\n",
    "                       years=[\"2019\"],\n",
    "                       train_test_split_by=\"start\",\n",
    "                       output_path=\"/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcom.apple.launchd.82pLsk9OX7\u001b[m\u001b[m statcast_pitches.db\r\n",
      "\u001b[34mcom.google.Keystone\u001b[m\u001b[m          t.py\r\n",
      "mappers_2019_2019.pkl        test_2019.csv\r\n",
      "\u001b[34mpowerlog\u001b[m\u001b[m                     train_2019.csv\r\n",
      "\u001b[34mrecsim\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/tmp/train_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols.remove(\"end_inning\")\n",
    "feature_cols.remove(\"postouts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[feature_cols]\n",
    "y = train[\"pulled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98     33873\n",
      "         1.0       0.66      0.21      0.32      1529\n",
      "\n",
      "    accuracy                           0.96     35402\n",
      "   macro avg       0.81      0.60      0.65     35402\n",
      "weighted avg       0.95      0.96      0.95     35402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, log_reg.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_bat_score: -0.2191\n",
      "score_diff: -0.0956\n",
      "inning: -1.6752\n",
      "cum_sb_ratio: -0.1784\n",
      "times_thru_order: 2.6153\n",
      "post_total_runners: 0.3159\n",
      "tying_run_on: -0.0041\n",
      "pitch_total: 2.2531\n",
      "post_opposite_hand: -0.0808\n",
      "walk: -0.0201\n",
      "walk_cumsum: -0.0988\n",
      "strikeout_cumsum: -0.0804\n",
      "home_run_cumsum: 0.3591\n",
      "bases_cumsum: -0.3573\n"
     ]
    }
   ],
   "source": [
    "for col, coef in zip(feature_cols, log_reg.coef_[0]):\n",
    "    print(f\"{col}: {round(coef, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem appears to be with `postouts`/`end_inning`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see how many co-occurences there are of `postouts==3` and `pulled==1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
