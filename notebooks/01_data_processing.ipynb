{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "> Functions to clean, transform, and aggregate the raw pitch-level data to the at-bat level, in addition to engineering some useful features.\n",
    "\n",
    "For more information on each field in the statcast data, see their [documentation](https://baseballsavant.mlb.com/csv-docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def query_db(db_path: str = \"../data/raw/statcast_pitches.db\",\n",
    "             year: str = \"2019\",\n",
    "             columns: str = \"*\",\n",
    "             limit=None,\n",
    "             verbose=True):\n",
    "    if verbose:\n",
    "        print(f\"querying db at {db_path} now.\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    query = f\"\"\"select {columns}\n",
    "                from statcast_{year}\"\"\"\n",
    "    if limit:\n",
    "        query += f\" limit {limit}\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify all eligible game-pitcher combinations\n",
    "\n",
    "This largely means filtering out [openers](https://www.theringer.com/mlb/2019/3/25/18280667/opener-war-warp-ryan-yarbrough-tampa-bay-rays-relief-pitchers)\n",
    "\n",
    "* As [defined by Tom Tango](http://tangotiger.com/index.php/site/comments/does-war-need-to-be-adjusted-for-the-opener#29), an opener is an pitcher that starts the game and either\n",
    "    - records less than or equal to 6 outs\n",
    "    - faces less than or equal to 9 batters\n",
    "\n",
    "For games where there was an \"opener\", I choose to drop the game entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# utility functions for identifying openers\n",
    "\n",
    "\n",
    "def postouts(df):\n",
    "    \"\"\"assumes sorted game pitcher df\"\"\"\n",
    "    # put assert here to ensure that the df is sorted and is all of the same pitcher\n",
    "    df[\"postouts\"] = df[\"outs_when_up\"].shift(-1).fillna(method=\"ffill\")\n",
    "\n",
    "    # if the inning changed, then the postouts is 3\n",
    "    df.loc[(df[\"inning\"] != df[\"inning\"].shift(-1)), \"postouts\"] = 3\n",
    "    return df\n",
    "\n",
    "\n",
    "def outs_per_inning(x: pd.Series):\n",
    "    \"\"\"assumes df came straight out of postouts()\"\"\"\n",
    "    # use should be: t.groupby([\"inning\"]).agg({\"postouts\": outs_per_inning})\n",
    "    return (x - x.shift(1).fillna(0)).sum()\n",
    "\n",
    "\n",
    "def batters_faced(at_bats: pd.Series):\n",
    "    return len(at_bats.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_games_pitchers_years(df: pd.DataFrame, verbose: bool):\n",
    "    \"\"\"\n",
    "    Filter out openers to get all game-pitcher combinations that qualify\n",
    "    \"\"\"\n",
    "    # get unique game ids from regular season games w/ AL starting pitchers\n",
    "    games = np.sort(df.loc[(df[\"game_type\"]==\"R\"), \"game_pk\"].unique())\n",
    "    if verbose:\n",
    "        print(f\"In this dataset, there are {len(games)} total games.\")\n",
    "    \n",
    "    # This will be list of tuples for each game and pitcher to analyze\n",
    "    games_pitchers_years = []\n",
    "\n",
    "    # identifying \"opener\" candidates\n",
    "    for game in games:\n",
    "        # getting df of game data and saving year\n",
    "        game_df = df.loc[(df[\"game_pk\"]==game)]\n",
    "        year = int(game_df[\"game_year\"].iloc[0])\n",
    "\n",
    "        # first pitcher for each team is throwing at min(at_bat_number)\n",
    "        home_pitcher_first_ab = game_df.loc[(game_df[\"inning_topbot\"]==\"Bot\"), \"at_bat_number\"].min()\n",
    "        home_pitcher = game_df.loc[(game_df[\"at_bat_number\"]==home_pitcher_first_ab), \"pitcher\"].head(1).item()\n",
    "\n",
    "        away_pitcher_first_ab = game_df.loc[(game_df[\"inning_topbot\"]==\"Top\", \"at_bat_number\")].min()\n",
    "        away_pitcher = game_df.loc[(game_df[\"at_bat_number\"]==away_pitcher_first_ab), \"pitcher\"].head(1).item()\n",
    "\n",
    "        # check if either are \"openers\"\n",
    "        for pitcher in (home_pitcher, away_pitcher):\n",
    "\n",
    "            # getting sorted df for specific game and specific pitcher\n",
    "            game_pitcher_df = game_df.loc[(game_df[\"pitcher\"]==pitcher)].sort_values(\"at_bat_number\", ascending=True)\n",
    "\n",
    "            # adding postouts\n",
    "            game_pitcher_df = postouts(game_pitcher_df)\n",
    "            outs = game_pitcher_df.groupby([\"inning\"]).agg({\"postouts\": outs_per_inning}).sum().item()\n",
    "            n_batters = batters_faced(game_pitcher_df[\"at_bat_number\"])\n",
    "            opener = outs < 7 or n_batters < 10\n",
    "            if not opener:\n",
    "                games_pitchers_years.append((game, pitcher, year))\n",
    "              \n",
    "    if verbose:\n",
    "        print(f\"There are {(len(games)*2) - len(games_pitchers_years)} 'openers' in the dataset.\")\n",
    "        print(f\"There are {len(games_pitchers_years)} total eligible game-pitcher combinations in this dataset.\")\n",
    "\n",
    "    return games_pitchers_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate to at-bat level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def preliminary_clean(df: pd.DataFrame, g: int, p: int):\n",
    "    \"\"\"\n",
    "    Before aggregating, perform a preliminary cleaning of dataset\n",
    "    \"\"\"\n",
    "    temp = df.loc[(df[\"game_pk\"]==g) & (df[\"pitcher\"]==p)].sort_values(\"at_bat_number\", ascending=True)\n",
    "\n",
    "    # adding postouts as a column\n",
    "    temp = postouts(temp)\n",
    "\n",
    "    # filling missing events with empty string so can aggregate easily\n",
    "    temp[\"events\"] = temp[\"events\"].fillna(\"\")\n",
    "\n",
    "    # post_bat_score is not actually score after at-bat, needs to be lagged\n",
    "    temp[\"post_bat_score\"] = temp[\"post_bat_score\"].shift(-1).fillna(method=\"ffill\")\n",
    "\n",
    "    # post runners on (need to lag -> this info is known in between at-bats)\n",
    "    temp[\"post_on_1b\"] = temp[\"on_1b\"].fillna(0).apply(lambda x: 1 if x>0 else 0).shift(-1).fillna(method=\"ffill\")\n",
    "    temp[\"post_on_2b\"] = temp[\"on_2b\"].fillna(0).apply(lambda x: 1 if x>0 else 0).shift(-1).fillna(method=\"ffill\")\n",
    "    temp[\"post_on_3b\"] = temp[\"on_3b\"].fillna(0).apply(lambda x: 1 if x>0 else 0).shift(-1).fillna(method=\"ffill\")\n",
    "\n",
    "    # if next batter opposite handed\n",
    "    temp[\"post_opposite_hand\"] = (temp[\"stand\"]!=temp[\"p_throws\"]).astype(int).shift(-1).fillna(method=\"ffill\")\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def last(x: pd.Series):\n",
    "    \"\"\"\n",
    "    Used for getting last value in df.groupby.agg\n",
    "    \"\"\"\n",
    "    return x.iloc[-1]\n",
    "\n",
    "at_bat_aggs = {\"balls\": \"max\",\n",
    "                \"strikes\": \"max\",\n",
    "                \"pitch_number\": \"max\",\n",
    "                \"post_bat_score\": last,\n",
    "                \"post_fld_score\": last,\n",
    "                \"events\": \"max\",\n",
    "                \"postouts\": last,\n",
    "                \"post_on_1b\": last,\n",
    "                \"post_on_2b\": last,\n",
    "                \"post_on_3b\": last,\n",
    "                \"game_type\": last,\n",
    "                \"home_team\": last,\n",
    "                \"away_team\": last,\n",
    "                \"inning\": last,\n",
    "                \"inning_topbot\": last,\n",
    "               \"post_opposite_hand\": last,\n",
    "               \"game_year\": last}\n",
    "\n",
    "def aggregate_at_bats(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    assumes the df has come straight out of preliminary clean\n",
    "    \"\"\"\n",
    "    agged_df = df.groupby(by=[\"game_pk\", \"pitcher\", \"batter\", \"at_bat_number\"]).agg(at_bat_aggs).sort_values(by=\"at_bat_number\")\n",
    "    return agged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "# helper feature engineering funcs\n",
    "\n",
    "def create_indicator(df, col=\"events\", indicators=[], indicator_col_names=[]):\n",
    "    \"\"\"\n",
    "\n",
    "    :param col: string, column from which to create a new indicator column\n",
    "    :param indicators: each time indicator occurs in col, assign a 1 to the indicator column\n",
    "    :param indicator_col_names: name of new indicator columns\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not indicator_col_names:\n",
    "        indicator_col_names = indicators\n",
    "    for indicator, indicator_col_name in zip(indicators, indicator_col_names):\n",
    "        df[indicator_col_name] = 0\n",
    "        df.loc[(df[col] == indicator), indicator_col_name] = 1\n",
    "    return df\n",
    "\n",
    "def accumulate(df, col, agg_func=\"cumsum\"):\n",
    "    if not agg_func.startswith(\"cum\"):\n",
    "        raise Warning(\"Are you sure you want to accumulate with a non-cumulative aggregation function?\")\n",
    "\n",
    "    df[f\"{col}_{agg_func}\"] = df[col].agg([agg_func])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def feature_engineering(t: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Assuming df came straight out of aggregate_at_bats\n",
    "    \"\"\"\n",
    "    # strike-ball ratio\n",
    "    t[\"cum_balls\"] = t[\"balls\"].cumsum()\n",
    "    t[\"cum_strikes\"] = t[\"strikes\"].cumsum()\n",
    "    t[\"cum_sb_ratio\"] = t[\"cum_strikes\"] / (t[\"cum_balls\"] + 1)\n",
    "\n",
    "    # end of inning\n",
    "    t[\"end_inning\"] = t[\"postouts\"].apply(lambda x: 1 if (x==3) else 0)\n",
    "    \n",
    "    # times through order\n",
    "    t[\"times_thru_order\"] = [1/9*i for i in range(1, len(t)+1)]\n",
    "\n",
    "    # score diff\n",
    "    t[\"score_diff\"] = t[\"post_fld_score\"] - t[\"post_bat_score\"]\n",
    "\n",
    "    # post total runners\n",
    "    t[\"post_total_runners\"] = t[[\"post_on_1b\", \"post_on_2b\", \"post_on_3b\"]].sum(axis=1)\n",
    "\n",
    "    # tying run or leading run on base\n",
    "    t[\"tying_run_on\"] = ((t[\"score_diff\"].isin((0,1))) & (t[\"post_total_runners\"]>=1)).astype(int)\n",
    "\n",
    "    # pitch total\n",
    "    t[\"pitch_total\"] = t[\"pitch_number\"].cumsum()\n",
    "\n",
    "    # getting pitcher's team\n",
    "    if t[\"inning_topbot\"].iloc[0] == \"Bot\":\n",
    "        t[\"pitcher_team\"] = t[\"away_team\"]\n",
    "    else:\n",
    "        t[\"pitcher_team\"] = t[\"home_team\"]\n",
    "        \n",
    "    # collapsing grouped multi-index of pd dataframe\n",
    "    t = t.reset_index()\n",
    "    \n",
    "    # subsetting dataset to only get AL starting pitchers\n",
    "    AL_teams = ['MIN', 'CLE', 'DET', 'HOU', \n",
    "                'BOS',  'TOR', 'LAA',  'BAL', 'KC', \n",
    "                'NYY', 'CWS',  'TEX',  'TB','OAK', \n",
    "                'SEA']\n",
    "    t = t.loc[(t[\"pitcher_team\"].isin(AL_teams))]\n",
    "\n",
    "    # adding unique category for each team-year combo (for embeddings later)\n",
    "    t[\"pitcher_team_year\"] = t[\"pitcher_team\"] + \"_\" + t[\"game_year\"].astype(int).astype(str)\n",
    "    \n",
    "    # creating indicator cols for different events\n",
    "    t = create_indicator(t, col=\"events\", indicators=[\"strikeout\", \"walk\", \"single\", \"double\", \"triple\", \"home_run\"])\n",
    "    \n",
    "    # cumulative stats\n",
    "    cum_cols = [(\"strikeout\", \"cumsum\"),\n",
    "                (\"walk\", \"cumsum\"),\n",
    "                (\"single\", \"cumsum\"),\n",
    "                (\"double\", \"cumsum\"),\n",
    "                (\"triple\", \"cumsum\"),\n",
    "                (\"home_run\", \"cumsum\")]\n",
    "    for col, agg_func in cum_cols:\n",
    "        t = accumulate(t, col=col, agg_func=agg_func)\n",
    "\n",
    "    # cumulative bases\n",
    "    t[\"bases_cumsum\"] = t[\"walk_cumsum\"] + t[\"single_cumsum\"] + (2 * t[\"double_cumsum\"]) + \\\n",
    "                         (3 * t[\"triple_cumsum\"]) + (4 * t[\"home_run_cumsum\"])\n",
    "    \n",
    "    return t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
